


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Train a model &mdash; RSI-Segmentation 0.0.1 documentation</title>
  

  <link rel="shortcut icon" href="_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/readthedocs.css" type="text/css" />
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="next" title="Inference with pretrained models" href="inference.html" />
  <link rel="prev" title="Model Zoo Statistics" href="modelzoo_statistics.html" />
  <!-- Google Analytics -->
  <script type="text/javascript">
    var collapsedSections = [];
  </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://rsi-segmentation.readthedocs.io/en/latest"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/EarthNets/RSI-Segmentation/blob/main/demo/rsi_segmentation_tutorial.ipynb" target="_blank">Tutorial</a>
          </li>
          <li>
            <a href="https://github.com/EarthNets/RSI-Segmentation" target="_blank">GitHub</a>
          </li>
          <li>
            <a href="" target="_blank">About</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                EarthNets
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/Dataset4EO" target="_blank">
                  <span class="dropdown-title">Dataset4EO </span>
                  <p>Re-organize remote sensing datasets.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-Classification" target="_blank">
                  <span class="dropdown-title">RSI-Classification </span>
                  <p>Image/scene classification for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-Segmentation" target="_blank">
                  <span class="dropdown-title">RSI-Segmentation </span>
                  <p>Pixel-wise semantic segmentation for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-Detection" target="_blank">
                  <span class="dropdown-title">RSI-Detection </span>
                  <p>Object detection for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-ChangeDetection" target="_blank">
                  <span class="dropdown-title">RSI-ChangeDetection </span>
                  <p>Change detection for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-SelfSupervised" target="_blank">
                  <span class="dropdown-title">RSI-SelfSupervised </span>
                  <p>Self-supervised learning for RS images.</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="get_started.html#installation">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dataset Preparation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataset_prepare.html">Prepare datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">Benchmark and Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="modelzoo_statistics.html">Model Zoo Statistics</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quick Run</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Train a model</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Inference with pretrained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/config.html">Tutorial 1: Learn about Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/customize_datasets.html">Tutorial 2: Customize Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/data_pipeline.html">Tutorial 3: Customize Data Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/customize_models.html">Tutorial 4: Customize Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/training_tricks.html">Tutorial 5: Training Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/customize_runtime.html">Tutorial 6: Customize Runtime Settings</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Useful Tools and Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="useful_tools.html">Useful tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="useful_tools.html#miscellaneous">Miscellaneous</a></li>
<li class="toctree-l1"><a class="reference internal" href="useful_tools.html#model-serving">Model Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="useful_tools.html#confusion-matrix">Confusion Matrix</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions (FAQ)</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
            Docs
        </a> &gt;
      </li>

        
      <li>Train a model</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/train.md.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="train-a-model">
<h1>Train a model<a class="headerlink" href="#train-a-model" title="Permalink to this heading">¶</a></h1>
<p>MMSegmentation implements distributed training and non-distributed training,
which uses <code class="docutils literal notranslate"><span class="pre">MMDistributedDataParallel</span></code> and <code class="docutils literal notranslate"><span class="pre">MMDataParallel</span></code> respectively.</p>
<p>All outputs (log files and checkpoints) will be saved to the working directory,
which is specified by <code class="docutils literal notranslate"><span class="pre">work_dir</span></code> in the config file.</p>
<p>By default we evaluate the model on the validation set after some iterations, you can change the evaluation interval by adding the interval argument in the training config.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="mi">4000</span><span class="p">)</span>  <span class="c1"># This evaluate the model per 4000 iterations.</span>
</pre></div>
</div>
<p><strong>*Important*</strong>: The default learning rate in config files is for 4 GPUs and 2 img/gpu (batch size = 4x2 = 8).
Equivalently, you may also use 8 GPUs and 1 imgs/gpu since all models using cross-GPU SyncBN.</p>
<p>To trade speed with GPU memory, you may pass in <code class="docutils literal notranslate"><span class="pre">--cfg-options</span> <span class="pre">model.backbone.with_cp=True</span></code> to enable checkpoint in backbone.</p>
<section id="train-on-a-single-machine">
<h2>Train on a single machine<a class="headerlink" href="#train-on-a-single-machine" title="Permalink to this heading">¶</a></h2>
<section id="train-with-a-single-gpu">
<h3>Train with a single GPU<a class="headerlink" href="#train-with-a-single-gpu" title="Permalink to this heading">¶</a></h3>
<p>official support:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sh tools/dist_train.sh <span class="si">${</span><span class="nv">CONFIG_FILE</span><span class="si">}</span> <span class="m">1</span> <span class="o">[</span>optional arguments<span class="o">]</span>
</pre></div>
</div>
<p>experimental support (Convert SyncBN to BN):</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python tools/train.py <span class="si">${</span><span class="nv">CONFIG_FILE</span><span class="si">}</span> <span class="o">[</span>optional arguments<span class="o">]</span>
</pre></div>
</div>
<p>If you want to specify the working directory in the command, you can add an argument <code class="docutils literal notranslate"><span class="pre">--work-dir</span> <span class="pre">${YOUR_WORK_DIR}</span></code>.</p>
</section>
<section id="train-with-cpu">
<h3>Train with CPU<a class="headerlink" href="#train-with-cpu" title="Permalink to this heading">¶</a></h3>
<p>The process of training on the CPU is consistent with single GPU training if machine does not have GPU. If it has GPUs but not wanting to use it, we just need to disable GPUs before the training process.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span>-1
</pre></div>
</div>
<p>And then run the script <span class="xref myst">above</span>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The process of training on the CPU is consistent with single GPU training. We just need to disable GPUs before the training process.</p>
</div>
</section>
<section id="train-with-multiple-gpus">
<h3>Train with multiple GPUs<a class="headerlink" href="#train-with-multiple-gpus" title="Permalink to this heading">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sh tools/dist_train.sh <span class="si">${</span><span class="nv">CONFIG_FILE</span><span class="si">}</span> <span class="si">${</span><span class="nv">GPU_NUM</span><span class="si">}</span> <span class="o">[</span>optional arguments<span class="o">]</span>
</pre></div>
</div>
<p>Optional arguments are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--no-validate</span></code> (<strong>not suggested</strong>): By default, the codebase will perform evaluation at every k iterations during the training. To disable this behavior, use <code class="docutils literal notranslate"><span class="pre">--no-validate</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--work-dir</span> <span class="pre">${WORK_DIR}</span></code>: Override the working directory specified in the config file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--resume-from</span> <span class="pre">${CHECKPOINT_FILE}</span></code>: Resume from a previous checkpoint file (to continue the training process).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--load-from</span> <span class="pre">${CHECKPOINT_FILE}</span></code>: Load weights from a checkpoint file (to start finetuning for another task).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--deterministic</span></code>: Switch on “deterministic” mode which slows down training but the results are reproducible.</p></li>
</ul>
<p>Difference between <code class="docutils literal notranslate"><span class="pre">resume-from</span></code> and <code class="docutils literal notranslate"><span class="pre">load-from</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">resume-from</span></code> loads both the model weights and optimizer state including the iteration number.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">load-from</span></code> loads only the model weights, starts the training from iteration 0.</p></li>
</ul>
<p>An example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># checkpoints and logs saved in WORK_DIR=work_dirs/pspnet_r50-d8_512x512_80k_ade20k/</span>
<span class="c1"># If work_dir is not set, it will be generated automatically.</span>
sh tools/dist_train.sh configs/pspnet/pspnet_r50-d8_512x512_80k_ade20k.py <span class="m">8</span> --work_dir work_dirs/pspnet_r50-d8_512x512_80k_ade20k/ --deterministic
</pre></div>
</div>
<p><strong>Note</strong>: During training, checkpoints and logs are saved in the same folder structure as the config file under <code class="docutils literal notranslate"><span class="pre">work_dirs/</span></code>. Custom work directory is not recommended since evaluation scripts infer work directories from the config file name. If you want to save your weights somewhere else, please use symlink, for example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>ln -s <span class="si">${</span><span class="nv">YOUR_WORK_DIRS</span><span class="si">}</span> <span class="si">${</span><span class="nv">MMSEG</span><span class="si">}</span>/work_dirs
</pre></div>
</div>
</section>
<section id="launch-multiple-jobs-on-a-single-machine">
<h3>Launch multiple jobs on a single machine<a class="headerlink" href="#launch-multiple-jobs-on-a-single-machine" title="Permalink to this heading">¶</a></h3>
<p>If you launch multiple jobs on a single machine, e.g., 2 jobs of 4-GPU training on a machine with 8 GPUs, you need to specify different ports (29500 by default) for each job to avoid communication conflict. Otherwise, there will be error message saying <code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">Address</span> <span class="pre">already</span> <span class="pre">in</span> <span class="pre">use</span></code>.</p>
<p>If you use <code class="docutils literal notranslate"><span class="pre">dist_train.sh</span></code> to launch training jobs, you can set the port in commands with environment variable <code class="docutils literal notranslate"><span class="pre">PORT</span></code>.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3 <span class="nv">PORT</span><span class="o">=</span><span class="m">29500</span> sh tools/dist_train.sh <span class="si">${</span><span class="nv">CONFIG_FILE</span><span class="si">}</span> <span class="m">4</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">4</span>,5,6,7 <span class="nv">PORT</span><span class="o">=</span><span class="m">29501</span> sh tools/dist_train.sh <span class="si">${</span><span class="nv">CONFIG_FILE</span><span class="si">}</span> <span class="m">4</span>
</pre></div>
</div>
</section>
</section>
<section id="train-with-multiple-machines">
<h2>Train with multiple machines<a class="headerlink" href="#train-with-multiple-machines" title="Permalink to this heading">¶</a></h2>
<p>If you launch with multiple machines simply connected with ethernet, you can simply run following commands:</p>
<p>On the first machine:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">NNODES</span><span class="o">=</span><span class="m">2</span> <span class="nv">NODE_RANK</span><span class="o">=</span><span class="m">0</span> <span class="nv">PORT</span><span class="o">=</span><span class="nv">$MASTER_PORT</span> <span class="nv">MASTER_ADDR</span><span class="o">=</span><span class="nv">$MASTER_ADDR</span> sh tools/dist_train.sh <span class="nv">$CONFIG</span> <span class="nv">$GPUS</span>
</pre></div>
</div>
<p>On the second machine:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">NNODES</span><span class="o">=</span><span class="m">2</span> <span class="nv">NODE_RANK</span><span class="o">=</span><span class="m">1</span> <span class="nv">PORT</span><span class="o">=</span><span class="nv">$MASTER_PORT</span> <span class="nv">MASTER_ADDR</span><span class="o">=</span><span class="nv">$MASTER_ADDR</span> sh tools/dist_train.sh <span class="nv">$CONFIG</span> <span class="nv">$GPUS</span>
</pre></div>
</div>
<p>Usually it is slow if you do not have high speed networking like InfiniBand.</p>
</section>
<section id="manage-jobs-with-slurm">
<h2>Manage jobs with Slurm<a class="headerlink" href="#manage-jobs-with-slurm" title="Permalink to this heading">¶</a></h2>
<p>Slurm is a good job scheduling system for computing clusters. On a cluster managed by Slurm, you can use slurm_train.sh to spawn training jobs. It supports both single-node and multi-node training.</p>
<p>Train with multiple machines:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span><span class="nv">GPUS</span><span class="o">=</span><span class="si">${</span><span class="nv">GPUS</span><span class="si">}</span><span class="o">]</span> sh tools/slurm_train.sh <span class="si">${</span><span class="nv">PARTITION</span><span class="si">}</span> <span class="si">${</span><span class="nv">JOB_NAME</span><span class="si">}</span> <span class="si">${</span><span class="nv">CONFIG_FILE</span><span class="si">}</span> --work-dir <span class="si">${</span><span class="nv">WORK_DIR</span><span class="si">}</span>
</pre></div>
</div>
<p>Here is an example of using 16 GPUs to train PSPNet on the dev partition.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">GPUS</span><span class="o">=</span><span class="m">16</span> sh tools/slurm_train.sh dev pspr50 configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py work_dirs/pspnet_r50-d8_512x1024_40k_cityscapes/
</pre></div>
</div>
<p>When using ‘slurm_train.sh’ to start multiple tasks on a node, different ports need to be specified. Three settings are provided:</p>
<p>Option 1:</p>
<p>In <code class="docutils literal notranslate"><span class="pre">config1.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dist_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">29500</span><span class="p">)</span>
</pre></div>
</div>
<p>In <code class="docutils literal notranslate"><span class="pre">config2.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dist_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">29501</span><span class="p">)</span>
</pre></div>
</div>
<p>Then you can launch two jobs with config1.py and config2.py.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3 <span class="nv">GPUS</span><span class="o">=</span><span class="m">4</span> sh tools/slurm_train.sh <span class="si">${</span><span class="nv">PARTITION</span><span class="si">}</span> <span class="si">${</span><span class="nv">JOB_NAME</span><span class="si">}</span> config1.py tmp_work_dir_1
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">4</span>,5,6,7 <span class="nv">GPUS</span><span class="o">=</span><span class="m">4</span> sh tools/slurm_train.sh <span class="si">${</span><span class="nv">PARTITION</span><span class="si">}</span> <span class="si">${</span><span class="nv">JOB_NAME</span><span class="si">}</span> config2.py tmp_work_dir_2
</pre></div>
</div>
<p>Option 2:</p>
<p>You can set different communication ports without the need to modify the configuration file, but have to set the <code class="docutils literal notranslate"><span class="pre">cfg-options</span></code> to overwrite the default port in configuration file.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3 <span class="nv">GPUS</span><span class="o">=</span><span class="m">4</span> sh tools/slurm_train.sh <span class="si">${</span><span class="nv">PARTITION</span><span class="si">}</span> <span class="si">${</span><span class="nv">JOB_NAME</span><span class="si">}</span> config1.py tmp_work_dir_1 --cfg-options dist_params.port<span class="o">=</span><span class="m">29500</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">4</span>,5,6,7 <span class="nv">GPUS</span><span class="o">=</span><span class="m">4</span> sh tools/slurm_train.sh <span class="si">${</span><span class="nv">PARTITION</span><span class="si">}</span> <span class="si">${</span><span class="nv">JOB_NAME</span><span class="si">}</span> config2.py tmp_work_dir_2 --cfg-options dist_params.port<span class="o">=</span><span class="m">29501</span>
</pre></div>
</div>
<p>Option 3:</p>
<p>You can set the port in the command using the environment variable ‘MASTER_PORT’:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3 <span class="nv">GPUS</span><span class="o">=</span><span class="m">4</span> <span class="nv">MASTER_PORT</span><span class="o">=</span><span class="m">29500</span> sh tools/slurm_train.sh <span class="si">${</span><span class="nv">PARTITION</span><span class="si">}</span> <span class="si">${</span><span class="nv">JOB_NAME</span><span class="si">}</span> config1.py tmp_work_dir_1
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">4</span>,5,6,7 <span class="nv">GPUS</span><span class="o">=</span><span class="m">4</span> <span class="nv">MASTER_PORT</span><span class="o">=</span><span class="m">29501</span> sh tools/slurm_train.sh <span class="si">${</span><span class="nv">PARTITION</span><span class="si">}</span> <span class="si">${</span><span class="nv">JOB_NAME</span><span class="si">}</span> config2.py tmp_work_dir_2
</pre></div>
</div>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="inference.html" class="btn btn-neutral float-right" title="Inference with pretrained models" accesskey="n"
      rel="next">Next <img src="_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="modelzoo_statistics.html" class="btn btn-neutral" title="Model Zoo Statistics" accesskey="p"
      rel="prev"><img src="_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2022, EarthNets.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Train a model</a><ul>
<li><a class="reference internal" href="#train-on-a-single-machine">Train on a single machine</a><ul>
<li><a class="reference internal" href="#train-with-a-single-gpu">Train with a single GPU</a></li>
<li><a class="reference internal" href="#train-with-cpu">Train with CPU</a></li>
<li><a class="reference internal" href="#train-with-multiple-gpus">Train with multiple GPUs</a></li>
<li><a class="reference internal" href="#launch-multiple-jobs-on-a-single-machine">Launch multiple jobs on a single machine</a></li>
</ul>
</li>
<li><a class="reference internal" href="#train-with-multiple-machines">Train with multiple machines</a></li>
<li><a class="reference internal" href="#manage-jobs-with-slurm">Manage jobs with Slurm</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="./"
    src="_static/documentation_options.js"></script>
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
  <script src="_static/jquery.js"></script>
  <script src="_static/underscore.js"></script>
  <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="_static/doctools.js"></script>
  <script src="_static/clipboard.min.js"></script>
  <script src="_static/copybutton.js"></script>
  

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://rsi-segmentation.readthedocs.io/en/latest" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/EarthNets/RSI-Segmentation/blob/main/demo/rsi_segmentation_tutorial.ipynb" target="_blank">Tutorial</a>
          </li>
          <li>
            <a href="https://github.com/EarthNets/RSI-Segmentation" target="_blank">GitHub</a>
          </li>
          <li>
            <a href="" target="_blank">About</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>