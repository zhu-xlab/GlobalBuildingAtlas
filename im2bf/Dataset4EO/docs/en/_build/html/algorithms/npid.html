


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>NPID &mdash; RSI-SelfSupervised 0.9.2 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/readthedocs.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="ODC" href="odc.html" />
  <link rel="prev" title="MoCo v2" href="moco.html" />
  <!-- Google Analytics -->
  <script type="text/javascript">
    var collapsedSections = [];
  </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://rsi-segmentation.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/EarthNets/RSI-SelfSupervised/blob/main/demo/rsi_selfsupervised_tutorial.ipynb" target="_blank">Tutorial</a>
          </li>
          <li>
            <a href="https://github.com/EarthNets/RSI-SelfSupervised" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/open-mmlab/mmcv" target="_blank">
                  <span class="dropdown-title">MMCV </span>
                  <p>Foundational library for computer vision</p>
                </a>
              </div>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                EarthNets
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/Dataset4EO" target="_blank">
                  <span class="dropdown-title">Dataset4EO </span>
                  <p>Re-organize remote sensing datasets.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-Classification" target="_blank">
                  <span class="dropdown-title">RSI-Classification </span>
                  <p>Image/scene classification for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-Segmentation" target="_blank">
                  <span class="dropdown-title">RSI-Segmentation </span>
                  <p>Pixel-wise semantic segmentation for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-Detection" target="_blank">
                  <span class="dropdown-title">RSI-Detection </span>
                  <p>Object detection for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-ChangeDetection" target="_blank">
                  <span class="dropdown-title">RSI-ChangeDetection </span>
                  <p>Change detection for RS images.</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/EarthNets/RSI-SelfSupervised" target="_blank">
                  <span class="dropdown-title">RSI-SelfSupervised </span>
                  <p>Self-supervised learning for RS images.</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html#using-multiple-mmselfsup-versions">Using multiple MMSelfSup versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prepare_data.html">Prepare Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo.html">Model Zoo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/0_config.html">Tutorial 0: Learn about Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/1_new_dataset.html">Tutorial 1: Adding New Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/2_data_pipeline.html">Tutorial 2: Customize Data Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/3_new_module.html">Tutorial 3: Adding New Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/4_schedule.html">Tutorial 4: Customize Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/5_runtime.html">Tutorial 5: Customize Runtime Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/6_benchmarks.html">Tutorial 6: Run Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Algorithms</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="byol.html">BYOL</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep.html">DeepCluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="dense.html">DenseCL</a></li>
<li class="toctree-l1"><a class="reference internal" href="moco.html">MoCo v2</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">NPID</a></li>
<li class="toctree-l1"><a class="reference internal" href="odc.html">ODC</a></li>
<li class="toctree-l1"><a class="reference internal" href="rl.html">Relative Location</a></li>
<li class="toctree-l1"><a class="reference internal" href="rp.html">Rotation Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="simclr.html">SimCLR</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss.html">SimSiam</a></li>
<li class="toctree-l1"><a class="reference internal" href="swav.html">SwAV</a></li>
<li class="toctree-l1"><a class="reference internal" href="mocov3.html">MoCo v3</a></li>
<li class="toctree-l1"><a class="reference internal" href="mae.html">MAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="simmim.html">SimMIM</a></li>
<li class="toctree-l1"><a class="reference internal" href="barlowtwins.html">BarlowTwins</a></li>
<li class="toctree-l1"><a class="reference internal" href="cae.html">CAE</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compatibility.html">Differences between MMSelfSup and OpenSelfSup</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
            Docs
        </a> &gt;
      </li>

        
      <li>NPID</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/algorithms/npid.md.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="npid">
<h1>NPID<a class="headerlink" href="#npid" title="Permalink to this heading">¶</a></h1>
<blockquote>
<div><p><a class="reference external" href="https://arxiv.org/abs/1805.01978">Unsupervised Feature Learning via Non-Parametric Instance Discrimination</a></p>
</div></blockquote>
<!-- [ALGORITHM] -->
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Permalink to this heading">¶</a></h2>
<p>Neural net classifiers trained on data with annotated class labels can also capture apparent visual similarity among categories without being directed to do so. We study whether this observation can be extended beyond the conventional domain of supervised learning: Can we learn a good feature representation that captures apparent similar- ity among instances, instead of classes, by merely asking the feature to be discriminative of individual instances?</p>
<p>We formulate this intuition as a non-parametric classification problem at the instance-level, and use noise-contrastive estimation to tackle the computational challenges imposed by the large number of instance classes. Our experimental results demonstrate that, under unsupervised learning settings, our method surpasses the state-of-the-art on ImageNet classification by a large margin.</p>
<p>Our method is also remarkable for consistently improving test performance with more training data and better network architectures. By fine-tuning the learned feature, we further obtain competitive results for semi-supervised learning and object detection tasks. Our non-parametric model is highly compact: With 128 features per image, our method requires only 600MB storage for a million images, enabling fast nearest neighbour retrieval at the run time.</p>
<div align="center">
<img  src="https://user-images.githubusercontent.com/36138628/149722257-1651c283-ac68-4cdc-90e6-970d820529af.png" width="800" />
</div>
</section>
<section id="results-and-models">
<h2>Results and Models<a class="headerlink" href="#results-and-models" title="Permalink to this heading">¶</a></h2>
<p><strong>Back to <a class="reference external" href="https://github.com/open-mmlab/mmselfsup/blob/master/docs/en/model_zoo.md">model_zoo.md</a> to download models.</strong></p>
<p>In this page, we provide benchmarks as much as possible to evaluate our pre-trained models. If not mentioned, all models are pre-trained on ImageNet-1k dataset.</p>
<section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Permalink to this heading">¶</a></h3>
<p>The classification benchmarks includes 4 downstream task datasets, <strong>VOC</strong>, <strong>ImageNet</strong>,  <strong>iNaturalist2018</strong> and <strong>Places205</strong>. If not specified, the results are  Top-1 (%).</p>
<section id="voc-svm-low-shot-svm">
<h4>VOC SVM / Low-shot SVM<a class="headerlink" href="#voc-svm-low-shot-svm" title="Permalink to this heading">¶</a></h4>
<p>The <strong>Best Layer</strong> indicates that the best results are obtained from which layers feature map. For example, if the <strong>Best Layer</strong> is <strong>feature3</strong>, its best result is obtained from the second stage of ResNet (1 for stem layer, 2-5 for 4 stage layers).</p>
<p>Besides, k=1 to 96 indicates the hyper-parameter of Low-shot SVM.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Self-Supervised Config</th>
<th>Best Layer</th>
<th>SVM</th>
<th>k=1</th>
<th>k=2</th>
<th>k=4</th>
<th>k=8</th>
<th>k=16</th>
<th>k=32</th>
<th>k=64</th>
<th>k=96</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/selfsup/npid/npid_resnet50_8xb32-steplr-200e_in1k.py">resnet50_8xb32-steplr-200e</a></td>
<td>feature5</td>
<td>76.75</td>
<td>26.96</td>
<td>35.37</td>
<td>44.48</td>
<td>53.89</td>
<td>60.39</td>
<td>66.41</td>
<td>71.48</td>
<td>73.39</td>
</tr>
</tbody>
</table>
</section>
<section id="imagenet-linear-evaluation">
<h4>ImageNet Linear Evaluation<a class="headerlink" href="#imagenet-linear-evaluation" title="Permalink to this heading">¶</a></h4>
<p>The <strong>Feature1 - Feature5</strong> don’t have the GlobalAveragePooling, the feature map is pooled to the specific dimensions and then follows a Linear layer to do the classification. Please refer to <a class="reference external" href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/benchmarks/classification/imagenet/resnet50_mhead_linear-8xb32-steplr-90e_in1k.py">resnet50_mhead_linear-8xb32-steplr-90e_in1k</a> for details of config.</p>
<p>The <strong>AvgPool</strong> result is obtained from Linear Evaluation with GlobalAveragePooling. Please refer to <a class="reference external" href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/benchmarks/classification/imagenet/resnet50_linear-8xb32-steplr-100e_in1k.py">resnet50_linear-8xb32-steplr-100e_in1k</a> for details of config.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Self-Supervised Config</th>
<th>Feature1</th>
<th>Feature2</th>
<th>Feature3</th>
<th>Feature4</th>
<th>Feature5</th>
<th>AvgPool</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/selfsup/npid/npid_resnet50_8xb32-steplr-200e_in1k.py">resnet50_8xb32-steplr-200e</a></td>
<td>14.68</td>
<td>31.98</td>
<td>42.85</td>
<td>56.95</td>
<td>58.41</td>
<td>57.97</td>
</tr>
</tbody>
</table>
</section>
<section id="places205-linear-evaluation">
<h4>Places205 Linear Evaluation<a class="headerlink" href="#places205-linear-evaluation" title="Permalink to this heading">¶</a></h4>
<p>The <strong>Feature1 - Feature5</strong> don’t have the GlobalAveragePooling, the feature map is pooled to the specific dimensions and then follows a Linear layer to do the classification. Please refer to <a class="reference external" href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/benchmarks/classification/places205/resnet50_mhead_8xb32-steplr-28e_places205.py">resnet50_mhead_8xb32-steplr-28e_places205.py</a> for details of config.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Self-Supervised Config</th>
<th>Feature1</th>
<th>Feature2</th>
<th>Feature3</th>
<th>Feature4</th>
<th>Feature5</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/selfsup/npid/npid_resnet50_8xb32-steplr-200e_in1k.py">resnet50_8xb32-steplr-200e</a></td>
<td>19.98</td>
<td>34.86</td>
<td>41.59</td>
<td>48.43</td>
<td>48.71</td>
</tr>
</tbody>
</table>
</section>
<section id="imagenet-nearest-neighbor-classification">
<h4>ImageNet Nearest-Neighbor Classification<a class="headerlink" href="#imagenet-nearest-neighbor-classification" title="Permalink to this heading">¶</a></h4>
<p>The results are obtained from the features after GlobalAveragePooling. Here, k=10 to 200 indicates different number of nearest neighbors.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Self-Supervised Config</th>
<th>k=10</th>
<th>k=20</th>
<th>k=100</th>
<th>k=200</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/selfsup/npid/npid_resnet50_8xb32-steplr-200e_in1k.py">resnet50_8xb32-steplr-200e</a></td>
<td>42.9</td>
<td>44.0</td>
<td>43.2</td>
<td>42.2</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="detection">
<h3>Detection<a class="headerlink" href="#detection" title="Permalink to this heading">¶</a></h3>
<p>The detection benchmarks includes 2 downstream task datasets, <strong>Pascal VOC 2007 + 2012</strong> and <strong>COCO2017</strong>. This benchmark follows the evluation protocols set up by MoCo.</p>
<section id="pascal-voc-2007-2012">
<h4>Pascal VOC 2007 + 2012<a class="headerlink" href="#pascal-voc-2007-2012" title="Permalink to this heading">¶</a></h4>
<p>Please refer to <a class="reference external" href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/benchmarks/mmdetection/voc0712/faster_rcnn_r50_c4_mstrain_24k_voc0712.py">faster_rcnn_r50_c4_mstrain_24k_voc0712.py</a> for details of config.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Self-Supervised Config</th>
<th>AP50</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/selfsup/npid/npid_resnet50_8xb32-steplr-200e_in1k.py">resnet50_8xb32-steplr-200e</a></td>
<td>79.52</td>
</tr>
</tbody>
</table>
</section>
<section id="coco2017">
<h4>COCO2017<a class="headerlink" href="#coco2017" title="Permalink to this heading">¶</a></h4>
<p>Please refer to <a class="reference external" href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/benchmarks/mmdetection/coco/mask_rcnn_r50_fpn_mstrain_1x_coco.py">mask_rcnn_r50_fpn_mstrain_1x_coco.py</a> for details of config.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Self-Supervised Config</th>
<th>mAP(Box)</th>
<th>AP50(Box)</th>
<th>AP75(Box)</th>
<th>mAP(Mask)</th>
<th>AP50(Mask)</th>
<th>AP75(Mask)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/selfsup/npid/npid_resnet50_8xb32-steplr-200e_in1k.py">resnet50_8xb32-steplr-200e</a></td>
<td>38.5</td>
<td>57.7</td>
<td>42.0</td>
<td>34.6</td>
<td>54.8</td>
<td>37.1</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="segmentation">
<h3>Segmentation<a class="headerlink" href="#segmentation" title="Permalink to this heading">¶</a></h3>
<p>The segmentation benchmarks includes 2 downstream task datasets, <strong>Cityscapes</strong> and <strong>Pascal VOC 2012 + Aug</strong>. It follows the evluation protocols set up by MMSegmentation.</p>
<section id="pascal-voc-2012-aug">
<h4>Pascal VOC 2012 + Aug<a class="headerlink" href="#pascal-voc-2012-aug" title="Permalink to this heading">¶</a></h4>
<p>Please refer to <a class="reference external" href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/benchmarks/mmsegmentation/voc12aug/fcn_r50-d8_512x512_20k_voc12aug.py">fcn_r50-d8_512x512_20k_voc12aug.py</a> for details of config.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Self-Supervised Config</th>
<th>mIOU</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/open-mmlab/mmselfsup/blob/master/configs/selfsup/npid/npid_resnet50_8xb32-steplr-200e_in1k.py">resnet50_8xb32-steplr-200e</a></td>
<td>65.45</td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Permalink to this heading">¶</a></h2>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wu2018unsupervised</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Unsupervised feature learning via non-parametric instance discrimination}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X and Lin, Dahua}</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2018}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="odc.html" class="btn btn-neutral float-right" title="ODC" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="moco.html" class="btn btn-neutral" title="MoCo v2" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2022, EarthNets.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">NPID</a><ul>
<li><a class="reference internal" href="#abstract">Abstract</a></li>
<li><a class="reference internal" href="#results-and-models">Results and Models</a><ul>
<li><a class="reference internal" href="#classification">Classification</a><ul>
<li><a class="reference internal" href="#voc-svm-low-shot-svm">VOC SVM / Low-shot SVM</a></li>
<li><a class="reference internal" href="#imagenet-linear-evaluation">ImageNet Linear Evaluation</a></li>
<li><a class="reference internal" href="#places205-linear-evaluation">Places205 Linear Evaluation</a></li>
<li><a class="reference internal" href="#imagenet-nearest-neighbor-classification">ImageNet Nearest-Neighbor Classification</a></li>
</ul>
</li>
<li><a class="reference internal" href="#detection">Detection</a><ul>
<li><a class="reference internal" href="#pascal-voc-2007-2012">Pascal VOC 2007 + 2012</a></li>
<li><a class="reference internal" href="#coco2017">COCO2017</a></li>
</ul>
</li>
<li><a class="reference internal" href="#segmentation">Segmentation</a><ul>
<li><a class="reference internal" href="#pascal-voc-2012-aug">Pascal VOC 2012 + Aug</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#citation">Citation</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/jquery.js"></script>
  <script src="../_static/underscore.js"></script>
  <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
  <script src="../_static/doctools.js"></script>
  <script src="../_static/clipboard.min.js"></script>
  <script src="../_static/copybutton.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://rsi-segmentation.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/EarthNets/RSI-SelfSupervised/blob/main/demo/rsi_selfsupervised_tutorial.ipynb" target="_blank">Tutorial</a>
          </li>
          <li>
            <a href="https://github.com/EarthNets/RSI-SelfSupervised" target="_blank">GitHub</a>
          </li>
          <li class="resources-mobile-menu-title" >
            About
          </li>
          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://github.com/open-mmlab/mmcv" target="_blank">MMCV</a>
            </li>
          </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>